_-----------------------------print true??True----------------
-------------hashed is false????True----------
mc.LOAD_PRETRAINED_MODEL is True
size3, size3, size1, size32 
kernel_val.shape is (3, 3, 1, 32)
inputs.get_shape() is (100, 28, 28, 1)
Tfcheck !!! True ------  32 -------- conv
!!!!Tfc !!! True ------  32
-------- conv ------------
ncluster/block is 2048
ncoWeight/block is 1
cWeights.shape is 3, 3, 1, 32
==============let's see=================
nCluster is  65536
centro 0 is  65248
0 is  65248
0 percentange is  0.99560546875
nonzero is  288
==============let's see=================
1 is  288
1 percentange is  0.00439453125 or 1.0
2 is  0
2 percentange is  0.0 or 0.0
3 is  0
3 percentange is  0.0 or 0.0
4 is  0
4 percentange is  0.0 or 0.0
5 is  0
5 percentange is  0.0 or 0.0
6 is  0
6 percentange is  0.0 or 0.0
7 is  0
7 percentange is  0.0 or 0.0
8 is  0
8 percentange is  0.0 or 0.0
9 is  0
9 percentange is  0.0 or 0.0
10 is  0
10 percentange is  0.0 or 0.0
inputs?? Tensor("batch:0", shape=(100, 28, 28, 1), dtype=float32, device=/device:GPU:0)
kernel?? <tf.Variable 'conv1/weights:0' shape=(3, 3, 1, 32) dtype=float32_ref>
conv?? Tensor("conv1/convolution:0", shape=(100, 28, 28, 32), dtype=float32, device=/device:GPU:0)
inputs.get_shape() is (100, 28, 28, 32)
END :  (100, 14, 14, 32)
size3, size3, size32, size64 
kernel_val.shape is (3, 3, 32, 64)
inputs.get_shape() is (100, 14, 14, 32)
Tfcheck !!! True ------  64 -------- conv
!!!!Tfc !!! True ------  64
-------- conv ------------
ncluster/block is 1024
ncoWeight/block is 1
cWeights.shape is 3, 3, 32, 64
==============let's see=================
nCluster is  65536
centro 0 is  51902
0 is  51902
0 percentange is  0.791961669921875
nonzero is  13634
==============let's see=================
1 is  9861
1 percentange is  0.1504669189453125 or 0.7232653659967728
2 is  2929
2 percentange is  0.0446929931640625 or 0.21483057063224292
3 is  692
3 percentange is  0.01055908203125 or 0.05075546428047528
4 is  126
4 percentange is  0.001922607421875 or 0.009241601877658795
5 is  23
5 percentange is  0.0003509521484375 or 0.0016869590729059704
6 is  3
6 percentange is  4.57763671875e-05 or 0.000220038139944257
7 is  0
7 percentange is  0.0 or 0.0
8 is  0
8 percentange is  0.0 or 0.0
9 is  0
9 percentange is  0.0 or 0.0
10 is  0
10 percentange is  0.0 or 0.0
inputs?? Tensor("pool1/MaxPool:0", shape=(100, 14, 14, 32), dtype=float32, device=/device:GPU:0)
kernel?? <tf.Variable 'conv2/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref>
conv?? Tensor("conv2/convolution:0", shape=(100, 14, 14, 64), dtype=float32, device=/device:GPU:0)
inputs.get_shape() is (100, 14, 14, 64)
END :  (100, 7, 7, 64)
size3, size3, size64, size128 
kernel_val.shape is (3, 3, 64, 128)
inputs.get_shape() is (100, 7, 7, 64)
Tfcheck !!! True ------  64 -------- conv
!!!!Tfc !!! True ------  64
-------- conv ------------
ncluster/block is 1024
ncoWeight/block is 2
cWeights.shape is 3, 3, 64, 128
==============let's see=================
nCluster is  65536
centro 0 is  35284
0 is  35284
0 percentange is  0.53839111328125
nonzero is  30252
==============let's see=================
1 is  9638
1 percentange is  0.147064208984375 or 0.3185905064127992
2 is  10309
2 percentange is  0.1573028564453125 or 0.3407708581250826
3 is  3902
3 percentange is  0.059539794921875 or 0.12898320772180352
4 is  3415
4 percentange is  0.0521087646484375 or 0.11288509850588391
5 is  1294
5 percentange is  0.019744873046875 or 0.042774031468993785
6 is  940
6 percentange is  0.01434326171875 or 0.031072325796641546
7 is  355
7 percentange is  0.0054168701171875 or 0.01173476133809335
8 is  217
8 percentange is  0.0033111572265625 or 0.007173079465820442
9 is  93
9 percentange is  0.0014190673828125 or 0.0030741769139230463
10 is  59
10 percentange is  0.0009002685546875 or 0.0019502842787253736
inputs?? Tensor("pool2/MaxPool:0", shape=(100, 7, 7, 64), dtype=float32, device=/device:GPU:0)
kernel?? <tf.Variable 'conv3/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>
conv?? Tensor("conv3/convolution:0", shape=(100, 7, 7, 128), dtype=float32, device=/device:GPU:0)
inputs.get_shape() is (100, 7, 7, 128)
END :  (100, 4, 4, 128)
Tfcheck !!! True ------  64 -------- FC
!!!!Tfc !!! True ------  64
-------- FC ------------
ncluster/block is 4096
nhWeight/block is 32
==============let's see=================
nCluster is  262144
centro 0 is  0
0 is  0
0 percentange is  0.0
nonzero is  262144
==============let's see=================
1 is  0
1 percentange is  0.0 or 0.0
2 is  0
2 percentange is  0.0 or 0.0
3 is  13742
3 percentange is  0.05242156982421875 or 0.05242156982421875
4 is  82334
4 percentange is  0.31407928466796875 or 0.31407928466796875
5 is  96556
5 percentange is  0.3683319091796875 or 0.3683319091796875
6 is  60235
6 percentange is  0.22977828979492188 or 0.22977828979492188
7 is  8968
7 percentange is  0.034210205078125 or 0.034210205078125
8 is  309
8 percentange is  0.001178741455078125 or 0.001178741455078125
9 is  0
9 percentange is  0.0 or 0.0
10 is  0
10 percentange is  0.0 or 0.0
Tfcheck !!! True ------  5 -------- FC
!!!!Tfc !!! True ------  5
-------- FC ------------
ncluster/block is 250
nhWeight/block is 125
==============let's see=================
nCluster is  1250
centro 0 is  7
0 is  7
0 percentange is  0.0056
nonzero is  1243
==============let's see=================
1 is  23
1 percentange is  0.0184 or 0.01850362027353178
2 is  94
2 percentange is  0.0752 or 0.0756234915526951
3 is  191
3 percentange is  0.1528 or 0.15366049879324215
4 is  211
4 percentange is  0.1688 or 0.16975060337892195
5 is  242
5 percentange is  0.1936 or 0.19469026548672566
6 is  191
6 percentange is  0.1528 or 0.15366049879324215
7 is  137
7 percentange is  0.1096 or 0.11021721641190668
8 is  95
8 percentange is  0.076 or 0.07642799678197908
9 is  43
9 percentange is  0.0344 or 0.03459372485921158
10 is  16
10 percentange is  0.0128 or 0.012872083668543845
debug1.................................................add_forward__graph : end
debug2.................................................add_loss_graph : end
WRONG
tk:grads_vars is  [(<tf.Tensor 'gradients/AddN_4:0' shape=(3, 3, 1, 32) dtype=float32>, <tf.Variable 'conv1/weights:0' shape=(3, 3, 1, 32) dtype=float32_ref>), (<tf.Tensor 'gradients/AddN_3:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref>), (<tf.Tensor 'gradients/AddN_2:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'conv3/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>), (<tf.Tensor 'gradients/AddN_1:0' shape=(2048, 625) dtype=float32>, <tf.Variable 'dense1/weights:0' shape=(2048, 625) dtype=float32_ref>), (<tf.Tensor 'gradients/dense1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(625,) dtype=float32>, <tf.Variable 'dense1/biases:0' shape=(625,) dtype=float32_ref>), (<tf.Tensor 'gradients/AddN:0' shape=(625, 10) dtype=float32>, <tf.Variable 'dense2/weights:0' shape=(625, 10) dtype=float32_ref>), (<tf.Tensor 'gradients/dense2/BiasAdd_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>, <tf.Variable 'dense2/biases:0' shape=(10,) dtype=float32_ref>)]
0 trainable variable is !!!grad: Tensor("gradients/AddN_4:0", shape=(3, 3, 1, 32), dtype=float32, device=/device:GPU:0)
0 trainable variable is !!!var: <tf.Variable 'conv1/weights:0' shape=(3, 3, 1, 32) dtype=float32_ref>
1 trainable variable is !!!grad: Tensor("gradients/AddN_3:0", shape=(3, 3, 32, 64), dtype=float32, device=/device:GPU:0)
1 trainable variable is !!!var: <tf.Variable 'conv2/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref>
2 trainable variable is !!!grad: Tensor("gradients/AddN_2:0", shape=(3, 3, 64, 128), dtype=float32, device=/device:GPU:0)
2 trainable variable is !!!var: <tf.Variable 'conv3/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>
3 trainable variable is !!!grad: Tensor("gradients/AddN_1:0", shape=(2048, 625), dtype=float32, device=/device:GPU:0)
3 trainable variable is !!!var: <tf.Variable 'dense1/weights:0' shape=(2048, 625) dtype=float32_ref>
4 trainable variable is !!!grad: Tensor("gradients/dense1/BiasAdd_grad/tuple/control_dependency_1:0", shape=(625,), dtype=float32, device=/device:GPU:0)
4 trainable variable is !!!var: <tf.Variable 'dense1/biases:0' shape=(625,) dtype=float32_ref>
5 trainable variable is !!!grad: Tensor("gradients/AddN:0", shape=(625, 10), dtype=float32, device=/device:GPU:0)
5 trainable variable is !!!var: <tf.Variable 'dense2/weights:0' shape=(625, 10) dtype=float32_ref>
6 trainable variable is !!!grad: Tensor("gradients/dense2/BiasAdd_grad/tuple/control_dependency_1:0", shape=(10,), dtype=float32, device=/device:GPU:0)
6 trainable variable is !!!var: <tf.Variable 'dense2/biases:0' shape=(10,) dtype=float32_ref>
debug3...............................................add_train_graph : end
Successfully Imported ../0.data/MNIST/train-images.gz
Extracting ../0.data/MNIST/train-images.gz
Successfully Imported ../0.data/MNIST/train-labels.gz
Extracting ../0.data/MNIST/train-labels.gz
Successfully Imported ../0.data/MNIST/test-images.gz
Extracting ../0.data/MNIST/test-images.gz
Successfully Imported ../0.data/MNIST/test-labels.gz
Extracting ../0.data/MNIST/test-labels.gz
Accuracy :  0.09740000028163194
-----------what is loss : 3.492006301879883
2019-12-13 04:06:20.230264: step 0, loss = 3.49 (534.6 images/sec; 0.187 sec/batch)
-----------what is loss : 3.47727108001709
2019-12-13 04:06:20.478246: step 10, loss = 3.48 (1667.6 images/sec; 0.060 sec/batch)
-----------what is loss : 3.4732894897460938
2019-12-13 04:06:20.690897: step 20, loss = 3.47 (1654.5 images/sec; 0.060 sec/batch)
-----------what is loss : 3.4536657333374023
2019-12-13 04:06:20.903788: step 30, loss = 3.45 (1658.9 images/sec; 0.060 sec/batch)
-----------what is loss : 3.4220023155212402
2019-12-13 04:06:21.114148: step 40, loss = 3.42 (1661.4 images/sec; 0.060 sec/batch)
-----------what is loss : 3.384402275085449
2019-12-13 04:06:21.325043: step 50, loss = 3.38 (1654.7 images/sec; 0.060 sec/batch)
-----------what is loss : 3.3525140285491943
2019-12-13 04:06:21.541118: step 60, loss = 3.35 (1664.8 images/sec; 0.060 sec/batch)
-----------what is loss : 3.2222113609313965
2019-12-13 04:06:21.756433: step 70, loss = 3.22 (1643.4 images/sec; 0.061 sec/batch)
-----------what is loss : 2.9873411655426025
2019-12-13 04:06:21.975211: step 80, loss = 2.99 (1623.8 images/sec; 0.062 sec/batch)
-----------what is loss : 2.4640586376190186
2019-12-13 04:06:22.191697: step 90, loss = 2.46 (1631.2 images/sec; 0.061 sec/batch)
-----------what is loss : 1.6457960605621338
2019-12-13 04:06:22.408843: step 100, loss = 1.65 (1647.9 images/sec; 0.061 sec/batch)
-----------what is loss : 1.5626249313354492
2019-12-13 04:06:22.626011: step 110, loss = 1.56 (1568.0 images/sec; 0.064 sec/batch)
-----------what is loss : 1.3666025400161743
2019-12-13 04:06:22.851675: step 120, loss = 1.37 (1593.1 images/sec; 0.063 sec/batch)
-----------what is loss : 1.5383973121643066
2019-12-13 04:06:23.065993: step 130, loss = 1.54 (1601.5 images/sec; 0.062 sec/batch)
-----------what is loss : 1.402998685836792
2019-12-13 04:06:23.279484: step 140, loss = 1.40 (1665.6 images/sec; 0.060 sec/batch)
-----------what is loss : 1.3097147941589355
2019-12-13 04:06:23.492723: step 150, loss = 1.31 (1647.5 images/sec; 0.061 sec/batch)
-----------what is loss : 1.3295913934707642
2019-12-13 04:06:23.704936: step 160, loss = 1.33 (1653.8 images/sec; 0.060 sec/batch)
-----------what is loss : 1.2864673137664795
2019-12-13 04:06:23.916846: step 170, loss = 1.29 (1615.9 images/sec; 0.062 sec/batch)
-----------what is loss : 1.4276793003082275
2019-12-13 04:06:24.129756: step 180, loss = 1.43 (1641.9 images/sec; 0.061 sec/batch)
-----------what is loss : 1.285358190536499
2019-12-13 04:06:24.341741: step 190, loss = 1.29 (1653.4 images/sec; 0.060 sec/batch)
-----------what is loss : 1.3026586771011353
2019-12-13 04:06:24.554085: step 200, loss = 1.30 (1651.9 images/sec; 0.061 sec/batch)
-----------what is loss : 1.316881537437439
2019-12-13 04:06:24.766168: step 210, loss = 1.32 (1653.4 images/sec; 0.060 sec/batch)
-----------what is loss : 1.2963578701019287
2019-12-13 04:06:24.979998: step 220, loss = 1.30 (1631.0 images/sec; 0.061 sec/batch)
-----------what is loss : 1.159883975982666
2019-12-13 04:06:25.194517: step 230, loss = 1.16 (1626.5 images/sec; 0.061 sec/batch)
-----------what is loss : 1.2023283243179321
2019-12-13 04:06:25.408288: step 240, loss = 1.20 (1631.8 images/sec; 0.061 sec/batch)
-----------what is loss : 1.2218525409698486
2019-12-13 04:06:25.623450: step 250, loss = 1.22 (1640.8 images/sec; 0.061 sec/batch)
-----------what is loss : 1.1907427310943604
2019-12-13 04:06:25.905433: step 260, loss = 1.19 (777.7 images/sec; 0.129 sec/batch)
-----------what is loss : 3.4001669883728027
2019-12-13 04:06:26.123926: step 270, loss = 3.40 (1645.2 images/sec; 0.061 sec/batch)
-----------what is loss : 3.39089298248291
2019-12-13 04:06:26.337147: step 280, loss = 3.39 (1651.2 images/sec; 0.061 sec/batch)
-----------what is loss : 3.3830251693725586
2019-12-13 04:06:26.550175: step 290, loss = 3.38 (1659.8 images/sec; 0.060 sec/batch)
-----------what is loss : 3.37402606010437
2019-12-13 04:06:26.764477: step 300, loss = 3.37 (1631.5 images/sec; 0.061 sec/batch)
-----------what is loss : 3.377192497253418
2019-12-13 04:06:26.978430: step 310, loss = 3.38 (1645.3 images/sec; 0.061 sec/batch)
-----------what is loss : 3.36922550201416
2019-12-13 04:06:27.193172: step 320, loss = 3.37 (1652.0 images/sec; 0.061 sec/batch)
-----------what is loss : 3.358623743057251
2019-12-13 04:06:27.410263: step 330, loss = 3.36 (1640.8 images/sec; 0.061 sec/batch)
-----------what is loss : 3.3625359535217285
2019-12-13 04:06:27.627576: step 340, loss = 3.36 (1627.1 images/sec; 0.061 sec/batch)
-----------what is loss : 3.351616382598877
2019-12-13 04:06:27.844474: step 350, loss = 3.35 (1648.0 images/sec; 0.061 sec/batch)
-----------what is loss : 3.3440985679626465
2019-12-13 04:06:28.061885: step 360, loss = 3.34 (1637.7 images/sec; 0.061 sec/batch)
-----------what is loss : 3.3523218631744385
2019-12-13 04:06:28.281558: step 370, loss = 3.35 (1617.8 images/sec; 0.062 sec/batch)
-----------what is loss : 3.3427491188049316
2019-12-13 04:06:28.499332: step 380, loss = 3.34 (1644.5 images/sec; 0.061 sec/batch)
-----------what is loss : 3.339458465576172
2019-12-13 04:06:28.714485: step 390, loss = 3.34 (1640.5 images/sec; 0.061 sec/batch)
-----------what is loss : 3.3395941257476807
2019-12-13 04:06:28.928731: step 400, loss = 3.34 (1648.2 images/sec; 0.061 sec/batch)
-----------what is loss : 3.329068183898926
2019-12-13 04:06:29.143418: step 410, loss = 3.33 (1654.4 images/sec; 0.060 sec/batch)
-----------what is loss : 3.320514678955078
2019-12-13 04:06:29.359796: step 420, loss = 3.32 (1609.2 images/sec; 0.062 sec/batch)
-----------what is loss : 3.3134379386901855
2019-12-13 04:06:29.575621: step 430, loss = 3.31 (1633.6 images/sec; 0.061 sec/batch)
-----------what is loss : 3.3055129051208496
2019-12-13 04:06:29.797699: step 440, loss = 3.31 (1609.1 images/sec; 0.062 sec/batch)
-----------what is loss : 3.3117895126342773
2019-12-13 04:06:30.016725: step 450, loss = 3.31 (1625.4 images/sec; 0.062 sec/batch)
-----------what is loss : 3.3122386932373047
2019-12-13 04:06:30.229849: step 460, loss = 3.31 (1653.4 images/sec; 0.060 sec/batch)
-----------what is loss : 3.3059213161468506
2019-12-13 04:06:30.443365: step 470, loss = 3.31 (1653.6 images/sec; 0.060 sec/batch)
-----------what is loss : 3.300529956817627
2019-12-13 04:06:30.657225: step 480, loss = 3.30 (1656.0 images/sec; 0.060 sec/batch)
-----------what is loss : 3.290590763092041
2019-12-13 04:06:30.874133: step 490, loss = 3.29 (1643.1 images/sec; 0.061 sec/batch)
-----------what is loss : 3.2963380813598633
2019-12-13 04:06:31.088927: step 500, loss = 3.30 (1663.6 images/sec; 0.060 sec/batch)
-----------what is loss : 3.2837886810302734
2019-12-13 04:06:31.303858: step 510, loss = 3.28 (1655.6 images/sec; 0.060 sec/batch)
-----------what is loss : 3.2828142642974854
2019-12-13 04:06:31.523033: step 520, loss = 3.28 (1641.2 images/sec; 0.061 sec/batch)
-----------what is loss : 3.286510467529297
2019-12-13 04:06:31.780088: step 530, loss = 3.29 (1644.5 images/sec; 0.061 sec/batch)
-----------what is loss : 3.2842109203338623
2019-12-13 04:06:32.000327: step 540, loss = 3.28 (1619.2 images/sec; 0.062 sec/batch)
-----------what is loss : 3.270212173461914
2019-12-13 04:06:32.223012: step 550, loss = 3.27 (1619.4 images/sec; 0.062 sec/batch)
-----------what is loss : 3.2654480934143066
2019-12-13 04:06:32.441495: step 560, loss = 3.27 (1617.6 images/sec; 0.062 sec/batch)
-----------what is loss : 3.258010149002075
2019-12-13 04:06:32.659837: step 570, loss = 3.26 (1641.3 images/sec; 0.061 sec/batch)
-----------what is loss : 3.263007164001465
2019-12-13 04:06:32.874203: step 580, loss = 3.26 (1659.9 images/sec; 0.060 sec/batch)
-----------what is loss : 3.261101484298706
2019-12-13 04:06:33.087337: step 590, loss = 3.26 (1655.3 images/sec; 0.060 sec/batch)
-----------what is loss : 3.2617337703704834
2019-12-13 04:06:33.313043: step 600, loss = 3.26 (1377.5 images/sec; 0.073 sec/batch)
-----------what is loss : 3.259341239929199
2019-12-13 04:06:33.527420: step 610, loss = 3.26 (1660.1 images/sec; 0.060 sec/batch)
-----------what is loss : 3.241149425506592
2019-12-13 04:06:33.740070: step 620, loss = 3.24 (1656.4 images/sec; 0.060 sec/batch)
-----------what is loss : 3.2487664222717285
2019-12-13 04:06:33.958767: step 630, loss = 3.25 (1636.5 images/sec; 0.061 sec/batch)
-----------what is loss : 3.240839958190918
2019-12-13 04:06:34.178105: step 640, loss = 3.24 (1656.8 images/sec; 0.060 sec/batch)
-----------what is loss : 3.240602731704712
2019-12-13 04:06:34.392218: step 650, loss = 3.24 (1662.4 images/sec; 0.060 sec/batch)
-----------what is loss : 3.217926025390625
2019-12-13 04:06:34.605595: step 660, loss = 3.22 (1655.9 images/sec; 0.060 sec/batch)
-----------what is loss : 3.2304835319519043
2019-12-13 04:06:34.819665: step 670, loss = 3.23 (1660.6 images/sec; 0.060 sec/batch)
-----------what is loss : 3.2278008460998535
2019-12-13 04:06:35.034067: step 680, loss = 3.23 (1652.9 images/sec; 0.060 sec/batch)
-----------what is loss : 3.216667890548706
2019-12-13 04:06:35.246757: step 690, loss = 3.22 (1661.5 images/sec; 0.060 sec/batch)
-----------what is loss : 3.215831756591797
2019-12-13 04:06:35.461679: step 700, loss = 3.22 (1645.2 images/sec; 0.061 sec/batch)
-----------what is loss : 3.212310314178467
2019-12-13 04:06:35.683039: step 710, loss = 3.21 (1460.5 images/sec; 0.068 sec/batch)
-----------what is loss : 3.2055962085723877
2019-12-13 04:06:35.896878: step 720, loss = 3.21 (1658.5 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1895086765289307
2019-12-13 04:06:36.114613: step 730, loss = 3.19 (1643.5 images/sec; 0.061 sec/batch)
-----------what is loss : 3.197018623352051
2019-12-13 04:06:36.328759: step 740, loss = 3.20 (1663.4 images/sec; 0.060 sec/batch)
-----------what is loss : 3.196826219558716
2019-12-13 04:06:36.541883: step 750, loss = 3.20 (1661.0 images/sec; 0.060 sec/batch)
-----------what is loss : 3.200627088546753
2019-12-13 04:06:36.755730: step 760, loss = 3.20 (1652.7 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1948158740997314
2019-12-13 04:06:36.970760: step 770, loss = 3.19 (1657.2 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1954267024993896
2019-12-13 04:06:37.184792: step 780, loss = 3.20 (1664.3 images/sec; 0.060 sec/batch)
-----------what is loss : 3.176589012145996
2019-12-13 04:06:37.439775: step 790, loss = 3.18 (1653.8 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1839332580566406
2019-12-13 04:06:37.652434: step 800, loss = 3.18 (1655.6 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1745452880859375
2019-12-13 04:06:37.867815: step 810, loss = 3.17 (1657.4 images/sec; 0.060 sec/batch)
-----------what is loss : 3.182901382446289
2019-12-13 04:06:38.080741: step 820, loss = 3.18 (1649.3 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1706924438476562
2019-12-13 04:06:38.295265: step 830, loss = 3.17 (1623.0 images/sec; 0.062 sec/batch)
-----------what is loss : 3.1646904945373535
2019-12-13 04:06:38.509227: step 840, loss = 3.16 (1652.8 images/sec; 0.061 sec/batch)
-----------what is loss : 3.15566349029541
2019-12-13 04:06:38.722668: step 850, loss = 3.16 (1657.0 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1559367179870605
2019-12-13 04:06:38.937194: step 860, loss = 3.16 (1654.7 images/sec; 0.060 sec/batch)
-----------what is loss : 3.149998664855957
2019-12-13 04:06:39.165811: step 870, loss = 3.15 (1396.3 images/sec; 0.072 sec/batch)
-----------what is loss : 3.156449794769287
2019-12-13 04:06:39.386898: step 880, loss = 3.16 (1606.3 images/sec; 0.062 sec/batch)
-----------what is loss : 3.1473443508148193
2019-12-13 04:06:39.606623: step 890, loss = 3.15 (1654.2 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1456103324890137
2019-12-13 04:06:39.825277: step 900, loss = 3.15 (1650.5 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1483633518218994
2019-12-13 04:06:40.040904: step 910, loss = 3.15 (1652.0 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1522364616394043
2019-12-13 04:06:40.254198: step 920, loss = 3.15 (1670.5 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1475491523742676
2019-12-13 04:06:40.469154: step 930, loss = 3.15 (1665.3 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1410725116729736
2019-12-13 04:06:40.683679: step 940, loss = 3.14 (1653.2 images/sec; 0.060 sec/batch)
-----------what is loss : 3.135660171508789
2019-12-13 04:06:40.897678: step 950, loss = 3.14 (1658.5 images/sec; 0.060 sec/batch)
-----------what is loss : 3.119570732116699
2019-12-13 04:06:41.112796: step 960, loss = 3.12 (1652.5 images/sec; 0.061 sec/batch)
-----------what is loss : 3.114499568939209
2019-12-13 04:06:41.327583: step 970, loss = 3.11 (1658.6 images/sec; 0.060 sec/batch)
-----------what is loss : 3.115708351135254
2019-12-13 04:06:41.541879: step 980, loss = 3.12 (1659.0 images/sec; 0.060 sec/batch)
-----------what is loss : 3.106731414794922
2019-12-13 04:06:41.757160: step 990, loss = 3.11 (1663.1 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1178689002990723
2019-12-13 04:06:41.972849: step 1000, loss = 3.12 (1632.4 images/sec; 0.061 sec/batch)
-----------what is loss : 3.093022346496582
2019-12-13 04:06:42.220074: step 1010, loss = 3.09 (1631.8 images/sec; 0.061 sec/batch)
-----------what is loss : 3.0983595848083496
2019-12-13 04:06:42.434027: step 1020, loss = 3.10 (1650.4 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1175646781921387
2019-12-13 04:06:42.650336: step 1030, loss = 3.12 (1627.4 images/sec; 0.061 sec/batch)
-----------what is loss : 3.105471611022949
2019-12-13 04:06:42.863137: step 1040, loss = 3.11 (1656.7 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1104543209075928
2019-12-13 04:06:43.115576: step 1050, loss = 3.11 (1643.7 images/sec; 0.061 sec/batch)
-----------what is loss : 3.110194444656372
2019-12-13 04:06:43.329394: step 1060, loss = 3.11 (1652.0 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1120662689208984
2019-12-13 04:06:43.541488: step 1070, loss = 3.11 (1669.0 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1185972690582275
2019-12-13 04:06:43.755823: step 1080, loss = 3.12 (1663.9 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1115212440490723
2019-12-13 04:06:43.969952: step 1090, loss = 3.11 (1649.1 images/sec; 0.061 sec/batch)
-----------what is loss : 3.107372522354126
2019-12-13 04:06:44.183789: step 1100, loss = 3.11 (1647.2 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1145195960998535
2019-12-13 04:06:44.401228: step 1110, loss = 3.11 (1645.3 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1183950901031494
2019-12-13 04:06:44.616610: step 1120, loss = 3.12 (1669.3 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1189236640930176
2019-12-13 04:06:44.830254: step 1130, loss = 3.12 (1661.3 images/sec; 0.060 sec/batch)
-----------what is loss : 3.113640308380127
2019-12-13 04:06:45.043275: step 1140, loss = 3.11 (1652.8 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1087381839752197
2019-12-13 04:06:45.256957: step 1150, loss = 3.11 (1664.0 images/sec; 0.060 sec/batch)
-----------what is loss : 3.114302396774292
2019-12-13 04:06:45.477952: step 1160, loss = 3.11 (1464.3 images/sec; 0.068 sec/batch)
-----------what is loss : 3.1142308712005615
2019-12-13 04:06:45.692960: step 1170, loss = 3.11 (1635.8 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1128194332122803
2019-12-13 04:06:45.917724: step 1180, loss = 3.11 (1415.2 images/sec; 0.071 sec/batch)
-----------what is loss : 3.113940477371216
2019-12-13 04:06:46.133172: step 1190, loss = 3.11 (1659.9 images/sec; 0.060 sec/batch)
-----------what is loss : 3.114818572998047
2019-12-13 04:06:46.347486: step 1200, loss = 3.11 (1651.4 images/sec; 0.061 sec/batch)
-----------what is loss : 3.117750644683838
2019-12-13 04:06:46.563059: step 1210, loss = 3.12 (1633.0 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1192188262939453
2019-12-13 04:06:46.781871: step 1220, loss = 3.12 (1650.6 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1132373809814453
2019-12-13 04:06:46.999323: step 1230, loss = 3.11 (1645.3 images/sec; 0.061 sec/batch)
-----------what is loss : 3.099675178527832
2019-12-13 04:06:47.213477: step 1240, loss = 3.10 (1643.3 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1161909103393555
2019-12-13 04:06:47.428575: step 1250, loss = 3.12 (1662.5 images/sec; 0.060 sec/batch)
-----------what is loss : 3.108081817626953
2019-12-13 04:06:47.641801: step 1260, loss = 3.11 (1673.3 images/sec; 0.060 sec/batch)
-----------what is loss : 3.112149715423584
2019-12-13 04:06:47.858911: step 1270, loss = 3.11 (1644.7 images/sec; 0.061 sec/batch)
-----------what is loss : 3.117466926574707
2019-12-13 04:06:48.072253: step 1280, loss = 3.12 (1666.7 images/sec; 0.060 sec/batch)
-----------what is loss : 3.109435558319092
2019-12-13 04:06:48.285675: step 1290, loss = 3.11 (1663.4 images/sec; 0.060 sec/batch)
-----------what is loss : 3.119879722595215
2019-12-13 04:06:48.499392: step 1300, loss = 3.12 (1655.5 images/sec; 0.060 sec/batch)
-----------what is loss : 3.1074459552764893
2019-12-13 04:06:48.753217: step 1310, loss = 3.11 (1017.2 images/sec; 0.098 sec/batch)
-----------what is loss : 3.112483024597168
2019-12-13 04:06:48.973194: step 1320, loss = 3.11 (1502.5 images/sec; 0.067 sec/batch)
-----------what is loss : 3.113165855407715
2019-12-13 04:06:49.188626: step 1330, loss = 3.11 (1664.0 images/sec; 0.060 sec/batch)
-----------what is loss : 3.108170747756958
2019-12-13 04:06:49.404203: step 1340, loss = 3.11 (1642.1 images/sec; 0.061 sec/batch)
-----------what is loss : 3.0969269275665283
2019-12-13 04:06:49.618642: step 1350, loss = 3.10 (1637.6 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1169838905334473
2019-12-13 04:06:49.834774: step 1360, loss = 3.12 (1606.2 images/sec; 0.062 sec/batch)
-----------what is loss : 3.104665756225586
2019-12-13 04:06:50.065400: step 1370, loss = 3.10 (1388.3 images/sec; 0.072 sec/batch)
-----------what is loss : 3.1077237129211426
2019-12-13 04:06:50.289428: step 1380, loss = 3.11 (1625.7 images/sec; 0.062 sec/batch)
-----------what is loss : 3.1176490783691406
2019-12-13 04:06:50.504373: step 1390, loss = 3.12 (1652.2 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1035892963409424
2019-12-13 04:06:50.718889: step 1400, loss = 3.10 (1646.1 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1130869388580322
2019-12-13 04:06:50.934518: step 1410, loss = 3.11 (1639.8 images/sec; 0.061 sec/batch)
-----------what is loss : 3.109154224395752
2019-12-13 04:06:51.148115: step 1420, loss = 3.11 (1651.9 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1068341732025146
2019-12-13 04:06:51.363111: step 1430, loss = 3.11 (1646.4 images/sec; 0.061 sec/batch)
-----------what is loss : 3.1107749938964844
2019-12-13 04:06:51.576835: step 1440, loss = 3.11 (1662.7 images/sec; 0.060 sec/batch)
-----------what is loss : 3.12100887298584
2019-12-13 04:06:51.792681: step 1450, loss = 3.12 (1646.5 images/sec; 0.061 sec/batch)
-----------what is loss : 3.119795083999634
2019-12-13 04:06:52.005516: step 1460, loss = 3.12 (1661.2 images/sec; 0.060 sec/batch)
-----------what is loss : 3.101661205291748
2019-12-13 04:06:52.228687: step 1470, loss = 3.10 (1408.6 images/sec; 0.071 sec/batch)
-----------what is loss : 3.1113383769989014
2019-12-13 04:06:52.455601: step 1480, loss = 3.11 (1377.8 images/sec; 0.073 sec/batch)
-----------what is loss : 3.1234359741210938
2019-12-13 04:06:52.671347: step 1490, loss = 3.12 (1633.9 images/sec; 0.061 sec/batch)
optimization Finished
Accuracy :  0.11349999956786633
hash-num conv1   conv
hash-num weights
CONV!!!!!!!!!!!!
hash-num conv2   conv
hash-num weights
CONV!!!!!!!!!!!!
hash-num conv3   conv
hash-num weights
CONV!!!!!!!!!!!!
hash-num dense1   dense
hash-num weights
FCweights!!!!!!!!!!!!
hash-num dense1   dense
hash-num biases
FCbiases!!!!!!!!!!!!
hash-num dense2   dense
hash-num weights
FCweights!!!!!!!!!!!!
hash-num dense2   dense
hash-num biases
FCbiases!!!!!!!!!!!!
tuple_tem key is conv2
tuple_tem key is conv1
tuple_tem key is conv3
tuple_tem key is dense2
tuple_tem key is dense1
tuple_tem key is (3, 3, 32, 64)
tuple_tem key is (3, 3, 1, 32)
tuple_tem key is (3, 3, 64, 128)
tuple_tem key is (625, 10)
tuple_tem key is (10,)
tuple_tem key is (2048, 625)
tuple_tem key is (625,)
