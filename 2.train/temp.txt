_-----------------------------print true??False----------------
-------------hashed is false????False----------
mc.LOAD_PRETRAINED_MODEL is True
layer name is  (3, 3, 1, 32)
size3, size3, size1, size32 
kernel_val.shape is (3, 3, 1, 32)
inputs.get_shape() is (100, 28, 28, 1)
=============================================================================================================================================here!!!!!
inputs?? Tensor("batch:0", shape=(100, 28, 28, 1), dtype=float32, device=/device:GPU:0)
kernel?? <tf.Variable 'conv1/kernels:0' shape=(3, 3, 1, 32) dtype=float32_ref>
conv?? Tensor("conv1/convolution:0", shape=(100, 28, 28, 32), dtype=float32, device=/device:GPU:0)
END :  (100, 28, 28, 32)
inputs.get_shape() is (100, 28, 28, 32)
END :  (100, 14, 14, 32)
layer name is  (3, 3, 32, 64)
size3, size3, size32, size64 
kernel_val.shape is (3, 3, 32, 64)
inputs.get_shape() is (100, 14, 14, 32)
=============================================================================================================================================here!!!!!
inputs?? Tensor("pool1/MaxPool:0", shape=(100, 14, 14, 32), dtype=float32, device=/device:GPU:0)
kernel?? <tf.Variable 'conv2/kernels:0' shape=(3, 3, 32, 64) dtype=float32_ref>
conv?? Tensor("conv2/convolution:0", shape=(100, 14, 14, 64), dtype=float32, device=/device:GPU:0)
END :  (100, 14, 14, 64)
inputs.get_shape() is (100, 14, 14, 64)
END :  (100, 7, 7, 64)
layer name is  (3, 3, 64, 128)
size3, size3, size64, size128 
kernel_val.shape is (3, 3, 64, 128)
inputs.get_shape() is (100, 7, 7, 64)
=============================================================================================================================================here!!!!!
inputs?? Tensor("pool2/MaxPool:0", shape=(100, 7, 7, 64), dtype=float32, device=/device:GPU:0)
kernel?? <tf.Variable 'conv3/kernels:0' shape=(3, 3, 64, 128) dtype=float32_ref>
conv?? Tensor("conv3/convolution:0", shape=(100, 7, 7, 128), dtype=float32, device=/device:GPU:0)
END :  (100, 7, 7, 128)
inputs.get_shape() is (100, 7, 7, 128)
END :  (100, 4, 4, 128)
kernel_val.shape is (625, 2048)
inputs.get_shape() is (100, 4, 4, 128)
see this :  [[ 5.85005470e-02  3.46248411e-02  1.35524049e-01 ... -2.06027836e-01
  -8.53845254e-02 -6.88088462e-02]
 [ 4.42437269e-03  1.43762846e-02  1.69052005e-01 ... -1.73509777e-01
   1.49477333e-01 -2.60294154e-02]
 [-5.06215841e-02  2.22042307e-01  1.34115517e-02 ... -2.15411205e-02
   1.27968326e-01 -3.84016670e-02]
 ...
 [-1.89298112e-02 -1.84565280e-02 -3.53435166e-02 ... -1.11864479e-02
  -1.87166501e-02 -8.77667964e-03]
 [ 9.08574089e-02 -8.22565109e-02 -7.64592132e-03 ...  1.29892439e-01
  -7.05557541e-05  1.00044355e-01]
 [ 4.90320213e-02  9.33132172e-02  3.53040814e-01 ...  1.11013196e-01
  -1.83084503e-01 -9.42522213e-02]]
----------------------2!!!flatten------------------{},{},{} 4 4 128
----------------------2!!!flatten------------------{} (625, 2048)
=============================================================================================================================================here!!!!!
[[ 5.85005470e-02  4.42437269e-03 -5.06215841e-02 ... -1.89298112e-02
   9.08574089e-02  4.90320213e-02]
 [ 3.46248411e-02  1.43762846e-02  2.22042307e-01 ... -1.84565280e-02
  -8.22565109e-02  9.33132172e-02]
 [ 1.35524049e-01  1.69052005e-01  1.34115517e-02 ... -3.53435166e-02
  -7.64592132e-03  3.53040814e-01]
 ...
 [-2.06027836e-01 -1.73509777e-01 -2.15411205e-02 ... -1.11864479e-02
   1.29892439e-01  1.11013196e-01]
 [-8.53845254e-02  1.49477333e-01  1.27968326e-01 ... -1.87166501e-02
  -7.05557541e-05 -1.83084503e-01]
 [-6.88088462e-02 -2.60294154e-02 -3.84016670e-02 ... -8.77667964e-03
   1.00044355e-01 -9.42522213e-02]]
END :  (100, 625)
kernel_val.shape is (10, 625)
inputs.get_shape() is (100, 625)
see this :  [[-0.20568731 -0.08266604 -0.09425306 ...  0.00698203 -0.00922986
  -0.01937854]
 [-0.12477512 -0.03177567 -0.14480405 ... -0.02345018 -0.24127871
   0.00574012]
 [ 0.04275272 -0.18739665 -0.23988596 ... -0.02511984  0.10166045
  -0.16669269]
 ...
 [-0.06751459 -0.0322892   0.00901739 ... -0.00310415 -0.03667607
  -0.18606138]
 [-0.08396881 -0.02538307 -0.06755056 ... -0.00689984  0.09748204
   0.0443453 ]
 [ 0.03816819  0.12412584 -0.03953178 ... -0.00890281 -0.21084115
   0.08236497]]
=============================================================================================================================================here!!!!!
[[-0.20568731 -0.12477512  0.04275272 ... -0.06751459 -0.08396881
   0.03816819]
 [-0.08266604 -0.03177567 -0.18739665 ... -0.0322892  -0.02538307
   0.12412584]
 [-0.09425306 -0.14480405 -0.23988596 ...  0.00901739 -0.06755056
  -0.03953178]
 ...
 [ 0.00698203 -0.02345018 -0.02511984 ... -0.00310415 -0.00689984
  -0.00890281]
 [-0.00922986 -0.24127871  0.10166045 ... -0.03667607  0.09748204
  -0.21084115]
 [-0.01937854  0.00574012 -0.16669269 ... -0.18606138  0.0443453
   0.08236497]]
END :  (100, 10)
debug1.................................................add_forward__graph : end
debug2.................................................add_loss_graph : end
grad_vars size is  Tensor("gradients/AddN_4:0", shape=(3, 3, 1, 32), dtype=float32, device=/device:GPU:0)
0 trainable variable is !!!var: Tensor("gradients/AddN_4:0", shape=(3, 3, 1, 32), dtype=float32, device=/device:GPU:0)
0 trainable variable is !!!var: <tf.Variable 'conv1/kernels:0' shape=(3, 3, 1, 32) dtype=float32_ref>
1 trainable variable is !!!var: Tensor("gradients/AddN_3:0", shape=(3, 3, 32, 64), dtype=float32, device=/device:GPU:0)
1 trainable variable is !!!var: <tf.Variable 'conv2/kernels:0' shape=(3, 3, 32, 64) dtype=float32_ref>
2 trainable variable is !!!var: Tensor("gradients/AddN_2:0", shape=(3, 3, 64, 128), dtype=float32, device=/device:GPU:0)
2 trainable variable is !!!var: <tf.Variable 'conv3/kernels:0' shape=(3, 3, 64, 128) dtype=float32_ref>
3 trainable variable is !!!var: Tensor("gradients/AddN_1:0", shape=(2048, 625), dtype=float32, device=/device:GPU:0)
3 trainable variable is !!!var: <tf.Variable 'dense1/weights:0' shape=(2048, 625) dtype=float32_ref>
4 trainable variable is !!!var: Tensor("gradients/dense1/BiasAdd_grad/tuple/control_dependency_1:0", shape=(625,), dtype=float32, device=/device:GPU:0)
4 trainable variable is !!!var: <tf.Variable 'dense1/biases:0' shape=(625,) dtype=float32_ref>
5 trainable variable is !!!var: Tensor("gradients/AddN:0", shape=(625, 10), dtype=float32, device=/device:GPU:0)
5 trainable variable is !!!var: <tf.Variable 'dense2/weights:0' shape=(625, 10) dtype=float32_ref>
6 trainable variable is !!!var: Tensor("gradients/dense2/BiasAdd_grad/tuple/control_dependency_1:0", shape=(10,), dtype=float32, device=/device:GPU:0)
6 trainable variable is !!!var: <tf.Variable 'dense2/biases:0' shape=(10,) dtype=float32_ref>
debug3...............................................add_train_graph : end
Successfully Imported ../0.data/MNIST/train-images.gz
Extracting ../0.data/MNIST/train-images.gz
Successfully Imported ../0.data/MNIST/train-labels.gz
Extracting ../0.data/MNIST/train-labels.gz
Successfully Imported ../0.data/MNIST/test-images.gz
Extracting ../0.data/MNIST/test-images.gz
Successfully Imported ../0.data/MNIST/test-labels.gz
Extracting ../0.data/MNIST/test-labels.gz
Accuracy :  0.9931000059843064
-----------what is loss : 4.55655574798584
2019-12-06 06:56:33.047118: step 0, loss = 4.56 (804.5 images/sec; 0.124 sec/batch)
-----------what is loss : 4.518955707550049
2019-12-06 06:56:33.161569: step 10, loss = 4.52 (2214.6 images/sec; 0.045 sec/batch)
-----------what is loss : 4.4473419189453125
2019-12-06 06:56:33.238645: step 20, loss = 4.45 (1992.5 images/sec; 0.050 sec/batch)
-----------what is loss : 4.364973545074463
2019-12-06 06:56:33.310168: step 30, loss = 4.36 (2221.2 images/sec; 0.045 sec/batch)
-----------what is loss : 4.279994010925293
2019-12-06 06:56:33.382243: step 40, loss = 4.28 (2208.4 images/sec; 0.045 sec/batch)
-----------what is loss : 4.19522762298584
2019-12-06 06:56:33.456663: step 50, loss = 4.20 (2188.7 images/sec; 0.046 sec/batch)
-----------what is loss : 4.111637115478516
2019-12-06 06:56:33.528349: step 60, loss = 4.11 (2221.5 images/sec; 0.045 sec/batch)
-----------what is loss : 4.029538154602051
2019-12-06 06:56:33.599834: step 70, loss = 4.03 (2214.7 images/sec; 0.045 sec/batch)
-----------what is loss : 3.9490160942077637
2019-12-06 06:56:33.670014: step 80, loss = 3.95 (2240.1 images/sec; 0.045 sec/batch)
-----------what is loss : 3.870082378387451
2019-12-06 06:56:33.753006: step 90, loss = 3.87 (1740.5 images/sec; 0.057 sec/batch)
-----------what is loss : 3.7927193641662598
2019-12-06 06:56:33.823535: step 100, loss = 3.79 (2224.8 images/sec; 0.045 sec/batch)
-----------what is loss : 3.7168993949890137
2019-12-06 06:56:33.894537: step 110, loss = 3.72 (2195.7 images/sec; 0.046 sec/batch)
-----------what is loss : 3.642594575881958
2019-12-06 06:56:33.964983: step 120, loss = 3.64 (2233.5 images/sec; 0.045 sec/batch)
-----------what is loss : 3.5697758197784424
2019-12-06 06:56:34.035515: step 130, loss = 3.57 (2229.5 images/sec; 0.045 sec/batch)
-----------what is loss : 3.4984116554260254
2019-12-06 06:56:34.106251: step 140, loss = 3.50 (2232.0 images/sec; 0.045 sec/batch)
-----------what is loss : 3.4284744262695312
2019-12-06 06:56:34.176237: step 150, loss = 3.43 (2240.0 images/sec; 0.045 sec/batch)
-----------what is loss : 3.3599355220794678
2019-12-06 06:56:34.246439: step 160, loss = 3.36 (2233.3 images/sec; 0.045 sec/batch)
-----------what is loss : 3.2927660942077637
2019-12-06 06:56:34.316508: step 170, loss = 3.29 (2231.7 images/sec; 0.045 sec/batch)
-----------what is loss : 3.2269399166107178
2019-12-06 06:56:34.387134: step 180, loss = 3.23 (2231.3 images/sec; 0.045 sec/batch)
-----------what is loss : 3.162431240081787
2019-12-06 06:56:34.458350: step 190, loss = 3.16 (2233.5 images/sec; 0.045 sec/batch)
-----------what is loss : 3.099210023880005
2019-12-06 06:56:34.541173: step 200, loss = 3.10 (1727.8 images/sec; 0.058 sec/batch)
-----------what is loss : 3.037256956100464
2019-12-06 06:56:34.610924: step 210, loss = 3.04 (2235.0 images/sec; 0.045 sec/batch)
-----------what is loss : 2.9765357971191406
2019-12-06 06:56:34.682388: step 220, loss = 2.98 (2236.3 images/sec; 0.045 sec/batch)
-----------what is loss : 2.917032480239868
2019-12-06 06:56:34.752492: step 230, loss = 2.92 (2225.2 images/sec; 0.045 sec/batch)
-----------what is loss : 2.8587186336517334
2019-12-06 06:56:34.822073: step 240, loss = 2.86 (2233.7 images/sec; 0.045 sec/batch)
-----------what is loss : 2.8015825748443604
2019-12-06 06:56:34.892147: step 250, loss = 2.80 (2225.2 images/sec; 0.045 sec/batch)
-----------what is loss : 2.745570659637451
2019-12-06 06:56:34.962333: step 260, loss = 2.75 (2224.8 images/sec; 0.045 sec/batch)
-----------what is loss : 2.690706968307495
2019-12-06 06:56:35.032673: step 270, loss = 2.69 (2231.3 images/sec; 0.045 sec/batch)
-----------what is loss : 2.636929750442505
2019-12-06 06:56:35.103272: step 280, loss = 2.64 (2217.8 images/sec; 0.045 sec/batch)
-----------what is loss : 2.5842580795288086
2019-12-06 06:56:35.173481: step 290, loss = 2.58 (2231.4 images/sec; 0.045 sec/batch)
-----------what is loss : 2.53261399269104
2019-12-06 06:56:35.244247: step 300, loss = 2.53 (2219.9 images/sec; 0.045 sec/batch)
-----------what is loss : 2.4819626808166504
2019-12-06 06:56:35.314444: step 310, loss = 2.48 (2228.9 images/sec; 0.045 sec/batch)
